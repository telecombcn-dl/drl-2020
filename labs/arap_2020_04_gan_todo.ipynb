{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ARAP_2020_04_gan_todo.ipynb","provenance":[{"file_id":"1Vu1zlPTk3R7fixarGgZdWwVLvLfAPXT3","timestamp":1606038974516},{"file_id":"1yWBcY4rLQccLEvzif9hv6Xpl0xdyL_wW","timestamp":1605993546646},{"file_id":"10Vu2oF8jnM98Mg35EpyZWZ2rGD0VZp0x","timestamp":1593438154247},{"file_id":"1aJ4r4iTMIzp-oYJOGLt06PAUvKAazeAq","timestamp":1593423341051},{"file_id":"1S5OihzFAYRk9pFYNcbCJGKfYSqe0R-G3","timestamp":1575298098352}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MbRVQ73oRVAO"},"source":["# DCGAN\n","\n","\n","In this notebook will learn about Generative Adversarial Networks by implementing a DCGAN to generate images from noise. \n","\n","**Important:** Set the Colab environment to run on GPU\n","\n","**Notebook created by [Daniel Fojo](https://www.linkedin.com/in/daniel-fojo/) for the [Postgraduate course in artificial intelligence with deep learning](https://www.talent.upc.edu/ing/estudis/formacio/curs/310400/postgrau-artificial-intelligence-deep-learning/) in [UPC School](https://www.talent.upc.edu/ing/) (2020).**\n","\n"]},{"cell_type":"code","metadata":{"id":"NcZGU22N9IX2"},"source":["import torch\n","from torch import nn, optim\n","from torchvision import transforms, datasets, utils\n","from PIL import Image\n","import numpy as np\n","import math\n","from IPython.display import display\n","from tqdm import tqdm\n","device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S_wpixTJ9fde"},"source":["## Hyperparameters"]},{"cell_type":"code","metadata":{"id":"HCW_8O999hAm"},"source":["num_epochs = 300\n","\n","lr = 0.0002\n","betas = (0.5, 0.999)\n","\n","noise_size = 100\n","batch_size = 128\n","num_val_samples = 25\n","num_classes = 10\n","num_input_channels = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1AaRIWR9L5m"},"source":["## Dataset\n","Download and prepare dataset\n"]},{"cell_type":"code","metadata":{"id":"UPMYeOfU9SyD"},"source":["train_transforms = transforms.Compose(\n","            [   \n","                transforms.Resize(32),\n","                transforms.ToTensor(),\n","                transforms.Normalize((0.5,), (.5,))\n","            ])\n","dataset = datasets.MNIST(root='data', train=True, transform=train_transforms, download=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QDFqjh4T9a7W"},"source":["## Data Loader\n","Create a data loader for the MNIST dataset"]},{"cell_type":"code","metadata":{"id":"TKNGNOBQ9U4w"},"source":["dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"--drGQMaGeop"},"source":["# DCGAN"]},{"cell_type":"markdown","metadata":{"id":"MFEBhsZb96T7"},"source":["## Networks\n","First, lets define our simple generator"]},{"cell_type":"markdown","metadata":{"id":"dD8ms_VzNmWn"},"source":["### Exercise 1\n","\n","The generator takes random noise as input and gives an image as output. Your exercise is to create the generator model.\n","\n","It should follow these guidelines:\n","* The input will be a vector with random noise of size `noise_size`\n","* You should first apply a fully connected with output size 512\\*4\\*4 (channels\\*height\\*width)\n","* Then you should apply 3 blocks of:\n","    * TransposedConvolution with kernel size 4, stride 2 and padding 1. For the first 2 blocks, the output channels should be 256 and 128. For the third block, the output channels should be the correct one to generate images of the dataset.\n","    * BatchNorm2d except for the last block.\n","    * ReLU activation for the first 2 blocks and Tanh for the third block.\n","\n","**Hint**: Remember to use reshape where necessary"]},{"cell_type":"code","metadata":{"id":"yA2vnc-G9-Nl"},"source":["class Generator(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","      \n","        self.fc = ...\n","   \n","        self.convt1 = nn.Sequential(\n","            ...\n","        )\n","        self.convt2 = nn.Sequential(\n","           ...\n","        )\n","        self.convt3 = nn.Sequential(\n","            ...\n","        )\n","\n","    def forward(self, x):\n","        ...\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LnSOu07Q-FLh"},"source":["Similarly lets define a simple discriminator"]},{"cell_type":"markdown","metadata":{"id":"9BQFM-vIPHvj"},"source":["### Exercise 2\n","\n","The discriminator takes an image as input and classifies it between Real or Fake (1 or 0). Your exercise is to create the discriminator model.\n","\n","It should follow these guidelines:\n","* The input will be an image of size `[num_input_channels, 32, 32]`\n","* You should apply 3 blocks of:\n","    * Convolution with kernel size 4, stride 2 and padding 1. The output channels should be 128, 256 and 512.\n","    * BatchNorm2d except for the first block.\n","    * LeakyReLU activation (alpha=0.2)\n","* Then you should first apply a fully connected with input size 512\\*4\\*4 (channels\\*height\\*width) and the correct output size and activation for binary classification\n","\n","\n","**Hint**: Remember to use reshape/flatten where necessary"]},{"cell_type":"code","metadata":{"id":"fI6fdck8-Q2N"},"source":["class Discriminator(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.conv1 = nn.Sequential(\n","            ...\n","        )\n","        self.conv2 = nn.Sequential(\n","            ...\n","        )\n","        self.conv3 = nn.Sequential(\n","            ...\n","        )\n","        \n","        self.fc = nn.Sequential(\n","           ... \n","        )\n","\n","    def forward(self, x):\n","        ...\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpmnuKnAeKjY"},"source":["generator = Generator().to(device)\n","optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)\n","\n","discriminator = Discriminator().to(device)\n","optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n","\n","criterion = nn.BCELoss()\n","\n","def init_weights(m):\n","    if type(m) in {nn.Conv2d, nn.ConvTranspose2d, nn.Linear}:\n","        torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)\n","        if m.bias != None:\n","            torch.nn.init.constant_(m.bias, 0.0)\n","    if type(m) == nn.BatchNorm2d:\n","        nn.init.normal_(m.weight, 1.0, 0.02)\n","        nn.init.constant_(m.bias, 0)\n","\n","generator.apply(init_weights)\n","discriminator.apply(init_weights);\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VNKQKA4FfCL7"},"source":["## Train function"]},{"cell_type":"markdown","metadata":{"id":"ryDTioLaSd_t"},"source":["### Exercise 3\n","\n","Complete the code. Take into account which labels should be used at each step of the training."]},{"cell_type":"code","metadata":{"id":"rp8UARzzfECJ"},"source":["def train_batch(real_samples, generator, discriminator, optimizer_g, optimizer_d):\n","\n","    generator.train()\n","    discriminator.train()\n","    \n","    current_batch_size = real_samples.shape[0]\n","    label_real = torch.ones(current_batch_size, 1, device=device)\n","    label_fake = torch.zeros(current_batch_size, 1, device=device)\n","\n","    ####################\n","    # OPTIMIZE GENERATOR\n","    ####################\n","\n","    # Reset gradients\n","    optimizer_g.zero_grad()\n","\n","    # Generate fake samples\n","    z = torch.randn(current_batch_size, noise_size, device=device)\n","    fake_samples = generator(z)\n","    \n","    # Evaluate the generated samples with the discriminator\n","    predictions_g_fake = discriminator(fake_samples)\n","\n","    # Calculate error with respect to what the generator wants\n","    loss_g = criterion(...)\n","\n","    # Backpropagate\n","    loss_g.backward()\n","    \n","    # Update weights\n","    optimizer_g.step()\n","    \n","    ####################\n","    # OPTIMIZE DISCRIMINATOR\n","    ####################\n","\n","    fake_samples = fake_samples.detach()\n","    # Reset gradients\n","    optimizer_d.zero_grad()\n","\n","    # Calculate discriminator prediction for real samples\n","    predictions_d_real = discriminator(real_samples)\n","\n","    # Calculate error with respect to what the discriminator wants\n","    loss_d_real = criterion(...)\n","\n","    # Calculate discriminator loss for fake samples\n","    predictions_d_fake = discriminator(fake_samples)\n","\n","    # Calculate error with respect to what the discriminator wants\n","    loss_d_fake = criterion(...)\n","    \n","    # Total discriminator loss\n","    loss_d = (loss_d_real + loss_d_fake) / 2\n","    loss_d.backward()\n","\n","    optimizer_d.step()\n","\n","    return loss_g.item(), loss_d.item()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VbBC3H3j0Yal"},"source":["## Evaluation function"]},{"cell_type":"code","metadata":{"id":"ZAokfOJ8iBpQ"},"source":["@torch.no_grad()\n","def evaluate(generator, z_val):\n","    generator.eval()\n","    fake_samples = generator(z_val).cpu()\n","    # select a sample or create grid if img is a batch\n","    nrows = int(math.sqrt(fake_samples.shape[0]))\n","    img = utils.make_grid(fake_samples, nrow=nrows)\n","\n","    # unnormalize\n","    img = (img*0.5 + 0.5)*255\n","\n","    # to numpy\n","    image_numpy = img.numpy().astype(np.uint8)\n","    image_numpy = np.transpose(image_numpy, (1, 2, 0))\n","    return Image.fromarray(image_numpy)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iWS0uvRJEHGd"},"source":["## Train loop"]},{"cell_type":"code","metadata":{"id":"pd3efLyTEQSE"},"source":["z_val = torch.randn(num_val_samples, noise_size, device=device)\n","\n","for epoch in range(num_epochs):\n","\n","    for i, (real_samples, labels) in enumerate(dataloader):\n","        real_samples = real_samples.to(device)\n","        loss_g, loss_d = train_batch(real_samples, generator, discriminator, optimizer_g, optimizer_d)\n","\n","        if i % 100 == 0:\n","            fake_images = evaluate(generator, z_val)\n","            display(fake_images)\n","\n","            # Show current loss\n","            print(f\"epoch: {epoch+1}/{num_epochs} batch: {i+1}/{len(dataloader)} G_loss: {loss_g}, D_loss: {loss_d}\")\n"],"execution_count":null,"outputs":[]}]}